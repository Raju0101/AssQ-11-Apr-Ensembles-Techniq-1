{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2240b486-a46b-47ab-9c77-cdac78129759",
   "metadata": {},
   "source": [
    "# AssQ 11-Apr Ensembel Techniq - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55636f23-a827-461a-a014-92e2e9e8af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is an ensemble technique in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357da53-96e5-4fc0-9957-f0e45701f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble methods are techniques that create multiple models and then combine them to produce improved results.\n",
    "Ensemble methods usually produces more accurate solutions than a single model would. \n",
    "This has been the case in a number of machine learning competitions, where the winning solutions used ensemble methods.\n",
    "\n",
    "Ensemble methods are techniques that aim at improving the accuracy of results in models by combining \n",
    "multiple models instead of using a single model.\n",
    "The combined models increase the accuracy of the results significantly. This has boosted the popularity of ensemble methods in machine learning.\n",
    "\n",
    "An example of an ensemble learning algorithm is bagging [2]. Given a learning algorithm for creating single\n",
    "predictive models and a data set, bagging creates diverse predictive models by\n",
    "feeding different uniform samples of the data set to the learning algorithm in order to create each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf80dd-19b1-4281-8f01-126a0b765e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1eab6-5280-4b94-84c2-f2f4d02ac15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Why are ensemble techniques used in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de4db0-0f39-4441-859f-a20482220625",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble methods are ideal for reducing the variance in models, thereby increasing the accuracy of predictions. \n",
    "The variance is eliminated when multiple models are combined to form a single prediction that is \n",
    "chosen from all other possible predictions from the combined models.\n",
    "\n",
    "What are the different types of ensemble methods in machine learning? Bagging, boosting, stacking, voting, blending,\n",
    "and cascading are the main types of ensemble methods in machine learning.\n",
    "\n",
    "Ensemble methods - The learning algorithms which construct a set of classifiers and then classify new \n",
    "data points by taking a choice of their predictions are known as Ensemble methods.\n",
    "Random forest is an ensemble model where number of decision trees is used to predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439d1ac-99a1-4986-a574-b5e73181d3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591fd28-9940-4fd6-8473-ed1c0c2128bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f915271-8368-487e-ac5c-4cc5e7218f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce variance within a noisy dataset.\n",
    "\n",
    "Bagging, also known as Bootstrap aggregating, is an ensemble learning technique that helps to\n",
    "improve the performance and accuracy of machine learning algorithms.\n",
    "It is used to deal with bias-variance trade-offs and reduces the variance of a prediction model.\n",
    "\n",
    "Bagging Is An Improvement On Majority Voting Principle\n",
    "\n",
    "When the samples are chosen, they are used to train and validate the predictions.\n",
    "The samples are then replaced back into the training set.\n",
    "The samples are selected at random. This technique is known as bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1024d-2056-4e08-91bc-3afdf89f36aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1de9d-7a1a-40ba-94a0-db8881bd96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is boosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f5907-873e-4693-9d81-2457b3b4c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Boosting is a method used in machine learning to reduce errors in predictive data analysis.\n",
    "Data scientists train machine learning software, called machine learning models, on labeled data to make guesses about unlabeled data.\n",
    "A single machine learning model might make prediction errors depending on the accuracy of the training dataset.\n",
    "For example, if a cat-identifying model has been trained only on images of white cats, it may occasionally misidentify a black cat.\n",
    "Boosting tries to overcome this issue by training multiple models sequentially to improve the accuracy of the overall system.\n",
    "\n",
    "\n",
    "Boosting is a method of merging different types of predictions.\n",
    "Bagging decreases variance, not bias, and solves over-fitting issues in a model. Boosting decreases bias, not variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c860db0-3a57-4624-a890-56ced76551d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497fdce-5fa7-4707-a3b0-f1999124a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are the benefits of using ensemble techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e3167-d0d0-42db-83db-92288f4d8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advantages/Benefits of ensemble methods\n",
    "Ensemble methods have higher predictive accuracy, compared to the individual models.\n",
    "Ensemble methods are very useful when there is both linear and non-linear type of data in the dataset;\n",
    "different models can be combined to handle this type of data.\n",
    "\n",
    "Ensemble learning is the process by which multiple models, such as classifiers or experts, are strategically\n",
    "generated and combined to solve a particular computational intelligence problem.\n",
    "Ensemble learning is primarily used to improve the (classification, prediction, function approximation, etc.)\n",
    "\n",
    "Interpretability is lost when ensemble model is used. The main purpose of bagging is to decrease the variance of learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df51ad-5a0d-4d1e-9a0e-540f3f7549ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62fe3d-af96-4100-86e3-2a0b1481d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Are ensemble techniques always better than individual models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31341609-1e90-4983-85f5-80622d52fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "There is no absolute guarantee a ensemble model performs better than an individual model, \n",
    "but if you build many of those, and your individual classifier is weak.\n",
    "Your overall performance should be better than an individual model.\n",
    "\n",
    "\n",
    "Ensemble methods have higher predictive accuracy, compared to the individual models .\n",
    "2. Ensemble methods are very useful when there is both\n",
    "linear and non-linear type of data in the dataset; different models can be combined to handle this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f472177-39f6-4cb8-ab6b-489c4a1aa1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542a37e-2f10-44ab-810c-b782e08db666",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How is the confidence interval calculated using bootstrap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e37da-e2da-4758-a7c1-6fdaf2eecd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculating Confidence Intervals with Bootstrapping\n",
    "Variance: It is obtained by the sum of squared distances between a data point and the mean for\n",
    "each data point divided by the number of data points.\n",
    "Standard Deviation: It is a measurement that shows us how our data points spread out from the mean.\n",
    "\n",
    "Methods for Bootstrapping Confidence Intervals\n",
    "Start with resampling with replacement from original data n times.\n",
    "For each bootstrap calculate mean x*.\n",
    "Compute δ* = x* − x for each bootstrap sample (x is mean of original data), sort them from smallest to biggest.\n",
    "Choose δ. 1 as the 90th percentile, δ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba05825-e809-4bce-9f9e-00796e5413c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How does bootstrap work and What are the steps involved in bootstrap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98c4f7-e400-4537-9c48-c643d2168d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bootstrap sampling is used in a machine learning ensemble algorithm called bootstrap aggregating (also called bagging).\n",
    "It helps in avoiding overfitting and improves the stability of machine learning algorithms.\n",
    "\n",
    "Particularly useful for assessing the quality of a machine learning model,\n",
    "bootstrapping is a method of inferring results for a population from results found on a \n",
    "collection of smaller random samples of the population, \n",
    "using replacement during the sampling process.\n",
    "\n",
    "Bootstrap is a free, open source front-end development framework for the creation of websites and web apps.\n",
    "Designed to enable responsive development of mobile-first websites,\n",
    "Bootstrap provides a collection of syntax for template designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d494014-739b-4628-85e6-a82bfbf770ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50cdc70-8db1-4867-86df-48156e0c121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a \n",
    "sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use \n",
    "bootstrap to estimate the 95% confidence interval for the population mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99c5a2-677d-4106-98eb-1bb0328155f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
